# And That Means Comfort: Optimizing Airbnb Listings (a tool for hosts)
#### by Gretchyn Drown, Paul Lankheet, and Patrick Murphy

## About
This Capstone project for the University of Michigan’s Master of Applied Data Science program aims to help Airbnb hosts maximize their booking opportunities by optimizing home attributes, descriptive terms, and pricing for their property. You can see this project in action [here](https://drive.google.com/file/d/1gWuza5l8nYSvGN-PuInj8UbI-9S4kqof/view?usp=share_link). Check our our [blog post](https://medium.com/@gdrown/and-that-means-comfort-optimizing-airbnb-listings-fbc0ce1e052d) for methodology information.

_Data access statement:_ Data is public domain and may be obtained from [Inside Airbnb](http://insideairbnb.com/get-the-data/). It is used under a [Creative Commons](https://creativecommons.org/licenses/by/4.0/) license.

_License:_ Use and distribution of all elements herein subject to [MIT Licensing](https://choosealicense.com/licenses/mit/).

_Built with_ [Python](https://www.python.org/), [MySQL](https://www.mysql.com/), [streamlit.io](https://streamlit.io/), and [AWS](https://aws.amazon.com/).

## Getting started
* Ensure that you have the latest version of Python installed.
* Download the Github files.
* Open the command line and navigate to where you saved the files.
* Use the code below to install the libraries needed for this project:
```
pip install -r --upgrade requirements.txt
```
* You will need to have a MySQL database on AWS; follow [this tutorial](https://aws.amazon.com/getting-started/hands-on/create-mysql-db/).


## Connecting to your database
* Create a secretsfile.py file that contains your personal information for your AWS database and ensure that it is located in the same directory as your Jupyter notebook. Use the following code, replacing the strings with your actual information:
```
secrets = {}
secrets['DATABASE_ENDPOINT'] = 'my_aws_database_url'
secrets['DATABASE_USER'] = 'my_username'
secrets['DATABASE_PASSWORD'] = 'my_password'
secrets['DATABASE_PORT'] = 'my_port'
secrets['DATABASE_NAME'] = 'my_db_name'
```
Now you can run the .py files.

## Loading up your database
First you will need to download the filenames.  The list of filenames included in this project represent the most recent data available at the time of project creation, and may not continue to be available in the future. Additionally, the filename list can be modified to focus on different cities, such as including non-US cities.  The list of files was generated by downloading the source code of the airbnb page shown above and mining the desired city links.

Second - you will need to run this file.
Data Loading/Data_Load_to_Sql_Stage_Including_file_download - Final Version.py

Note you will need to create tables in your database to accept the files.  It can be done by using the commented out to_sql line in function or manually. All Create statements have been added to the file SQl Tables

    #used to first create the database table
    #listing_detail.to_sql('listing_detail_stage',con=connection, if_exists='replace',index=False, chunksize=1000, method='multi')

2nd note - this will create a large amount of files in your data loading folder (as it downloads each csv)

## Data transformations
A number of data transformations/cleaning/views were created to support the analysis.  These can be found in the file
Data Transformation\SQl for Table and Views.sql

Next the file database loading amenities & reviews here
functions/Database Loading Amenities & Reviews.ipynb

will run the reviews and amenities scripts and save the data to the database.


## Creating and hosting your streamlit.io app
* Download the folder "app" from the repository.
* Open the command line and navigate to where you saved <About.py>.
* Run the following command:
```
streamlit run About.py
```
* To host your app on AWS, follow [this guide](https://towardsdatascience.com/how-to-deploy-a-streamlit-app-using-an-amazon-free-ec2-instance-416a41f69dc3), modifying as necessary. You will also need to upload the files in the "app" folder into your EC2 instance.

## You’re good to go!
