{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d773fd03-43ff-4427-b4e6-cbe2a3bbeb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets import our modules\n",
    "import boto3\n",
    "import pandas as pd\n",
    "#import psycopg2\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import sqlite3\n",
    "import sys\n",
    "parentDirectory = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.insert(0,parentDirectory)\n",
    "from secretsPaul import secrets\n",
    "import mysql.connector\n",
    "import plotly.express as px\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f95b1a2-0f01-44fb-8f1c-52342a267e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connections\n",
    "#def create_connection():\n",
    "endpoint = 'drown-murphy-lankheet.cluster-ceswqg9qwa9i.us-east-1.rds.amazonaws.com'#secrets.get('DATABASE_ENDPOINT')\n",
    "user = secrets.get('DATABASE_USER')\n",
    "password = secrets.get('DATABASE_PASSWORD')\n",
    "port=secrets.get('DATABASE_PORT')\n",
    "connection = create_engine(f'mysql+pymysql://{user}:{password}@{endpoint}:{port}/Capstone', pool_recycle=3600,  connect_args={'connect_timeout': 10});\n",
    "    \n",
    "connect=mysql.connector.connect(host=endpoint, database='Capstone', user=user, password=password)\n",
    "cursor = connect.cursor()\n",
    "    #return cursor\n",
    "#cursor=create_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c638a24-7ff5-45bf-bea7-cb583e87f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling in listings\n",
    "all_listings = pd.read_sql('Select scrape_city, amenities, review_scores_value  from recent_listings_occup',connection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eafc8f9-6c48-45e8-9135-8abe224be5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97021722-8cc8-46ef-8b87-b89077138ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NLP FUNCTIONS - Updated to handle looping\n",
    "\n",
    "def get_top_amenities(listing_df):\n",
    "    # correlating amenities with review scores\n",
    "    # adapted from https://stackoverflow.com/questions/48873233/is-there-a-way-to-get-correlation-with-string-data-and-a-numerical-value-in-pand\n",
    "\n",
    "    df = listing_df.copy()\n",
    "    amen_list = list(df['amenities'])\n",
    "\n",
    "    new_list = [item.strip('[]\\' \"\"').replace(' u2013 ', ': ').replace('u2019', \"'\").replace('\"', '') for item in\n",
    "                amen_list]\n",
    "\n",
    "    list_of_lists = []\n",
    "    for item in new_list:\n",
    "        new_item = item.split(\",\")\n",
    "        list_of_lists.append(new_item)\n",
    "\n",
    "    flattened = [val for sublist in list_of_lists for val in sublist]\n",
    "    counts = Counter(flattened)\n",
    "\n",
    "    high_counts = {k: c for k, c in counts.items() if c >= 500}\n",
    "\n",
    "    top_amen = list(high_counts.keys())\n",
    "\n",
    "    full_new_list = []\n",
    "    for each_list in list_of_lists:\n",
    "        new_new_list = list(set(top_amen).intersection(set(each_list)))\n",
    "        full_new_list.append(new_new_list)\n",
    "\n",
    "    df['amenities'] = full_new_list\n",
    "\n",
    "    s_corr = pd.DataFrame(df.amenities.str.get_dummies(sep=',').corrwith(\n",
    "        df.review_scores_value / df.review_scores_value.max()))\n",
    "    s_corr.reset_index(inplace=True)\n",
    "    s_corr.rename(columns={'index': 'amenity', 0: 'score'}, inplace=True)\n",
    "\n",
    "    for idx, item in enumerate(s_corr['amenity']):\n",
    "        s_corr.at[idx, 'amenity'] = s_corr.at[idx, 'amenity'].lower().strip('[]\\' \"\"')\n",
    "    s_corr = s_corr.sort_values(by='score', ascending=False)\n",
    "    s_corr['score'] = s_corr['score'].round(3)\n",
    "\n",
    "    amenities_df = s_corr.set_index('amenity')[:20]\n",
    "\n",
    "    return amenities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53c09d39-4ce4-4c36-a36b-3405678c4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique list of all cities\n",
    "scrape_list=list(all_listings['scrape_city'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9f68c30-4b26-4b1c-aa8a-30e3512ef72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through each city and running the amenities\n",
    "top_amenities=pd.DataFrame(columns=['amenity','score','scrape_city'])\n",
    "for city in scrape_list:\n",
    "    topa=get_top_amenities(all_listings[all_listings['scrape_city']==city])\n",
    "    topa['scrape_city']=city\n",
    "    topa.reset_index(inplace=True)\n",
    "    top_amenities=pd.concat([top_amenities, topa],ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef900e54-e793-423f-9f76-c2c3840c1c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_amenities.to_sql('top_amenities',con=connection, if_exists='replace',index=False, chunksize=1000, method='multi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
